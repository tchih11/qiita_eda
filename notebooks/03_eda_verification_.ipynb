{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_eda_verification .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4702638def3d43ec9bffe63e0f3572fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_52d4abcd64eb40929ce98f70128f21fb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c9883fb01a1b4d72bedb02201912ce11",
              "IPY_MODEL_99a3c6979b5a482089b4699a322e736f"
            ]
          }
        },
        "52d4abcd64eb40929ce98f70128f21fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c9883fb01a1b4d72bedb02201912ce11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_633986f8ede049f7addbbdf4622b9047",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 15683,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 15683,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_81e6d709bdcb49769a646f668cdcc5f5"
          }
        },
        "99a3c6979b5a482089b4699a322e736f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9b9aef06d3e54fbf966aaf971436e549",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 15.7k/15.7k [00:00&lt;00:00, 222kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_388e688ee6ef4b51bc847bbda5b05c08"
          }
        },
        "633986f8ede049f7addbbdf4622b9047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "81e6d709bdcb49769a646f668cdcc5f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b9aef06d3e54fbf966aaf971436e549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "388e688ee6ef4b51bc847bbda5b05c08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tchih11/qiita_eda/blob/main/notebooks/03_eda_verification_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LngtB6qtPxeB"
      },
      "source": [
        "# 各種インストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS1d3oIvQM6F",
        "outputId": "1781cb31-7d51-4f2e-d00f-cc7fdc4ea78a"
      },
      "source": [
        "!git clone https://tchih11:@github.com/tchih11/qiita_eda.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'qiita_eda'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 41 (delta 15), reused 6 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (41/41), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgZgOmhPZMx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06a2a4a6-6cbb-4398-9ea0-cdb44146c85b"
      },
      "source": [
        "# early stopping 用\r\n",
        "import os\r\n",
        "!git clone https://github.com/Bjarten/early-stopping-pytorch.git\r\n",
        "os.rename('early-stopping-pytorch','early_stopping_pytorch')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'early-stopping-pytorch'...\n",
            "remote: Enumerating objects: 92, done.\u001b[K\n",
            "remote: Total 92 (delta 0), reused 0 (delta 0), pack-reused 92\u001b[K\n",
            "Unpacking objects: 100% (92/92), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3GBfl75oVnh"
      },
      "source": [
        "%%capture\r\n",
        "!pip install transformers==3.5.1\r\n",
        "!pip install fugashi\r\n",
        "!pip install ipadic"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnRfgXSw1Y2p"
      },
      "source": [
        "import os\r\n",
        "import random\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import torch\r\n",
        "import torch.optim as optim\r\n",
        "from early_stopping_pytorch.pytorchtools import EarlyStopping\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from torch import nn\r\n",
        "from torch.utils.data import DataLoader, TensorDataset\r\n",
        "from tqdm import tqdm\r\n",
        "from transformers import BertForSequenceClassification\r\n",
        "from transformers.tokenization_bert_japanese import BertJapaneseTokenizer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXdJVhgYq9Z1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "4702638def3d43ec9bffe63e0f3572fe",
            "52d4abcd64eb40929ce98f70128f21fb",
            "c9883fb01a1b4d72bedb02201912ce11",
            "99a3c6979b5a482089b4699a322e736f",
            "633986f8ede049f7addbbdf4622b9047",
            "81e6d709bdcb49769a646f668cdcc5f5",
            "9b9aef06d3e54fbf966aaf971436e549",
            "388e688ee6ef4b51bc847bbda5b05c08"
          ]
        },
        "outputId": "d0f2a2ca-ec18-4755-d494-16d5e8692858"
      },
      "source": [
        "pretrained_model = 'cl-tohoku/bert-base-japanese-char-whole-word-masking'\r\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained(pretrained_model)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4702638def3d43ec9bffe63e0f3572fe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=15683.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLIMfUDFTOwL"
      },
      "source": [
        "# 関数の定義\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVJOTREx9_4j"
      },
      "source": [
        "def tokenizer_512(input_text):\r\n",
        "    \"\"\"\r\n",
        "    文章をtokenizeしてpytorchのTensorに変換\r\n",
        "\r\n",
        "    Args:\r\n",
        "        input_text (str): tokenizeしたい文章\r\n",
        "\r\n",
        "    Returns:\r\n",
        "        Tensor\r\n",
        "    \"\"\"    \r\n",
        "    return tokenizer.encode_plus(\r\n",
        "                    input_text,                      \r\n",
        "                    add_special_tokens = True,\r\n",
        "                    max_length = max_length,\r\n",
        "                    padding = \"max_length\",\r\n",
        "                    truncation=True,\r\n",
        "                    return_tensors = 'pt',\r\n",
        "                )[\"input_ids\"][0]\r\n",
        "\r\n",
        "def make_torch_dataset(df, text_col, label_col, tokenizer):\r\n",
        "    \"\"\"\r\n",
        "    pandasのDataFrameで作成したデータをtokenizeしてpytorchのTensorDatasetへ変換\r\n",
        "\r\n",
        "    Args:\r\n",
        "        df (DataFrame): TensorDatasetへ変換するDataFrame\r\n",
        "        text_col (str): DataFrameの文章が格納されているカラム名\r\n",
        "        label_col (str): DataFrameの正解ラベルが格納されているカラム名\r\n",
        "        tokenizer (function): 使用するtokenizer\r\n",
        "\r\n",
        "    Returns:\r\n",
        "        TensorDataset\r\n",
        "    \"\"\"\r\n",
        "    label = df[label_col]\r\n",
        "    input_ids = []\r\n",
        "    for item in df[text_col].apply(tokenizer):\r\n",
        "        text = item.view(1, -1)\r\n",
        "        input_ids.append(text)\r\n",
        "        \r\n",
        "    ids = torch.cat(input_ids, dim=0)\r\n",
        "    label = torch.tensor(list(label))\r\n",
        "    \r\n",
        "    return TensorDataset(ids, label)\r\n",
        "\r\n",
        "\r\n",
        "def stratified_train_test_split_split(df,label_col,test_size=0.2):\r\n",
        "    \"\"\"\r\n",
        "    DataFrameを層化分割\r\n",
        "    \r\n",
        "    Args:\r\n",
        "        df (DataFrame): DataFrameの正解ラベルが格納されているカラム名\r\n",
        "        label_col (str): DataFrameの正解ラベルが格納されているカラム名\r\n",
        "        test_size (float, optional): testの割合. Defaults to 0.2.\r\n",
        "\r\n",
        "    Returns:\r\n",
        "        DataFrame\r\n",
        "    \"\"\"\r\n",
        "    df.reset_index(drop=True,inplace=True)\r\n",
        "    train, eval = train_test_split(df,stratify=df[label_col],random_state=0,test_size=0.2)\r\n",
        "    train_df = df.loc[train.index]\r\n",
        "    eval_df = df.loc[eval.index]\r\n",
        "    return train_df, eval_df\r\n",
        "    \r\n",
        "\r\n",
        "def train_model(net, dl_train, dl_eval, device, criterion, optimizer, patience=3, batch_size=16, n_epochs=20):\r\n",
        "    \"\"\"\r\n",
        "    early stoppingを使用したモデルの学習。\r\n",
        "\r\n",
        "    Args:\r\n",
        "        net (model): 学習の元となるモデル\r\n",
        "        dl_train (DataLoader): train用のDataLoader\r\n",
        "        dl_eval (DataLoader): eval用のDataLoader\r\n",
        "        device (device): 使用するdevice\r\n",
        "        criterion (criterion): 使用する損失関数\r\n",
        "        optimizer (optim): 使用するoptimizer\r\n",
        "        patience (int, optional): 指定のepoch数、指標が改善しなければearly stopping. Defaults to 3.\r\n",
        "        batch_size (int, optional): バッチサイズ. Defaults to 16.\r\n",
        "        n_epochs (int, optional): エポック数. Defaults to 20.\r\n",
        "\r\n",
        "    Returns:\r\n",
        "        model\r\n",
        "    \"\"\"    \r\n",
        "\r\n",
        "    net.to(device)\r\n",
        "    batch_size = dl_train.batch_size\r\n",
        "\r\n",
        "    train_losses = []\r\n",
        "    valid_losses = []\r\n",
        "    avg_train_losses = []\r\n",
        "    avg_valid_losses = [] \r\n",
        "    \r\n",
        "    early_stopping = EarlyStopping(patience=patience, delta=0.005, verbose=True)\r\n",
        "    for epoch in tqdm(range(1, n_epochs + 1),total=n_epochs,position=0 ,leave=True, desc=\"train\"):\r\n",
        "        net.train()\r\n",
        "        for batch in dl_train:\r\n",
        "            data = batch[0].to(device)  # 文章\r\n",
        "            target = batch[1].to(device)  # ラベル\r\n",
        "            optimizer.zero_grad()\r\n",
        "            output = net(data)[0]\r\n",
        "            loss = criterion(output, target)\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "            train_losses.append(loss.item())\r\n",
        "\r\n",
        "        net.eval()\r\n",
        "        for batch in dl_eval:\r\n",
        "            data = batch[0].to(device)  # 文章\r\n",
        "            target = batch[1].to(device)  # ラベル\r\n",
        "            output = net(data)[0]\r\n",
        "            loss = criterion(output, target)\r\n",
        "            valid_losses.append(loss.item())\r\n",
        "\r\n",
        "        train_loss = np.average(train_losses)\r\n",
        "        valid_loss = np.average(valid_losses)\r\n",
        "        avg_train_losses.append(train_loss)\r\n",
        "        avg_valid_losses.append(valid_loss)\r\n",
        "        \r\n",
        "        epoch_len = len(str(n_epochs))\r\n",
        "        \r\n",
        "        print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\r\n",
        "                     f'train_loss: {train_loss:.5f} ' +\r\n",
        "                     f'valid_loss: {valid_loss:.5f}')\r\n",
        "        \r\n",
        "        print(print_msg)\r\n",
        "        \r\n",
        "        train_losses = []\r\n",
        "        valid_losses = []\r\n",
        "        \r\n",
        "        early_stopping(valid_loss, net)\r\n",
        "        \r\n",
        "        if early_stopping.early_stop:\r\n",
        "            print(\"Early stopping\")\r\n",
        "            break\r\n",
        "        \r\n",
        "    net.load_state_dict(torch.load('checkpoint.pt'))\r\n",
        "\r\n",
        "    return net\r\n",
        "\r\n",
        "def valid_test(net_trained, device, dl_test):\r\n",
        "    \"\"\"\r\n",
        "    testデータへ当てはめ、accuracyの算出\r\n",
        "\r\n",
        "    Args:\r\n",
        "        net_trained (model): 学習済みモデル\r\n",
        "        device (device): 使用するdevice\r\n",
        "        dl_test (DataLoader): test用のDataLoader\r\n",
        "\r\n",
        "    Returns:\r\n",
        "        float: testデータのaccuracy\r\n",
        "    \"\"\"    \r\n",
        "    net_trained.eval()\r\n",
        "    net_trained.to(device)\r\n",
        "    epoch_corrects = 0\r\n",
        "\r\n",
        "    for batch in tqdm(dl_test,position=0 ,leave=True,desc=\"predict\"):\r\n",
        "        data = batch[0].to(device)  # 文章\r\n",
        "        target = batch[1].to(device)  # ラベル\r\n",
        "\r\n",
        "        with torch.set_grad_enabled(False):\r\n",
        "            outputs = net_trained(data)[0]\r\n",
        "            _, preds = torch.max(outputs, 1)\r\n",
        "            epoch_corrects += torch.sum(preds == target)\r\n",
        "\r\n",
        "    epoch_acc = epoch_corrects.double() / len(dl_test.dataset)\r\n",
        "    return epoch_acc"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7GQqgSurotD"
      },
      "source": [
        "# 実行用\r\n",
        "def modeling(train_eval_df,test_df,num_epochs=20):\r\n",
        "    \r\n",
        "    # GPU設定\r\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "    # モデリング用データをtrainとevalに層化分割\r\n",
        "    train_df, eval_df = stratified_train_test_split_split(train_eval_df,label_col=\"label_index\")\r\n",
        "\r\n",
        "    # datasetに変換\r\n",
        "    dataset_train = make_torch_dataset(train_df, \"text\", \"label_index\", tokenizer_512)\r\n",
        "    dataset_eval = make_torch_dataset(eval_df, \"text\", \"label_index\", tokenizer_512)\r\n",
        "    dataset_test = make_torch_dataset(test_df, \"text\", \"label_index\", tokenizer_512)\r\n",
        "\r\n",
        "    # dataloader作成\r\n",
        "    torch.backends.cudnn.deterministic = True\r\n",
        "    torch.manual_seed(1)\r\n",
        "    dl_train = DataLoader(dataset_train,batch_size = batch_size)\r\n",
        "    dl_eval = DataLoader(dataset_eval,batch_size = batch_size)\r\n",
        "    dl_test = DataLoader(dataset_test,batch_size = batch_size)\r\n",
        "    \r\n",
        "    # モデル構築\r\n",
        "    net = BertForSequenceClassification.from_pretrained(pretrained_model, num_labels=9)\r\n",
        "    net.train()\r\n",
        "\r\n",
        "    # 重みを変更する個所\r\n",
        "    for param in net.parameters():\r\n",
        "        param.requires_grad = False\r\n",
        "    for param in net.bert.encoder.layer[-1].parameters():\r\n",
        "        param.requires_grad = True\r\n",
        "    for param in net.classifier.parameters():\r\n",
        "        param.requires_grad = True\r\n",
        "\r\n",
        "    # 最適化手法\r\n",
        "    optimizer = optim.Adam([\r\n",
        "        {'params': net.bert.encoder.layer[-1].parameters(), 'lr': 5e-5},\r\n",
        "        {'params': net.classifier.parameters(), 'lr': 1e-4}\r\n",
        "    ])\r\n",
        "\r\n",
        "    # 損失関数\r\n",
        "    criterion = nn.CrossEntropyLoss()      \r\n",
        "    \r\n",
        "    # 訓練実施\r\n",
        "    net_trained =  train_model(net, dl_train, dl_eval, device, criterion, optimizer)\r\n",
        "    \r\n",
        "    # テストデータで検証\r\n",
        "    epoch_acc = valid_test(net_trained, device, dl_test)\r\n",
        "    \r\n",
        "    return epoch_acc.item()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "up_RddXGI1F6"
      },
      "source": [
        "# モデリング、検証\r\n",
        "train dataは  \r\n",
        "*   データ数 = [500, 1000, 2000]  \r\n",
        "*   alpha = [0.05, 0.10]  \r\n",
        "*   aug_num = [0, 1, 4, 8, 16]  \r\n",
        "\r\n",
        "の全組み合わせを試すため、for文を回す。  \r\n",
        "※回りきらない可能性があるため、データ数は[500, 1000]と[2000]に分けるのがよい"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaAGf8rAV-G_"
      },
      "source": [
        "# パラメータの設定\r\n",
        "batch_size = 16\r\n",
        "max_length = 512\r\n",
        "\r\n",
        "# testデータの読み込み\r\n",
        "test_df = pd.read_pickle(\"/content/qiita_eda/data/test_df.pkl\")\r\n",
        "test_df.columns = [\"text\",\"label_index\"]\r\n",
        "\r\n",
        "# trainデータの設定\r\n",
        "pickles_path = [\r\n",
        "                \"/content/qiita_eda/data/train_eval_eda_2000_5_16_gzip.pkl\", # alpha=0.05で作成したデータセット\r\n",
        "                \"/content/qiita_eda/data/train_eval_eda_2000_10_16_gzip.pkl\" # alpha=0.10で作成したデータセット\r\n",
        "                ]                \r\n",
        "alpha_list = [5,10]\r\n",
        "sampling_list = [500, 1000]\r\n",
        "# sampling_list = [2000]\r\n",
        "num_agg_list = [0,1,4,8,16]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MDefSgZBC00"
      },
      "source": [
        "# 結果確認用\r\n",
        "result = pd.DataFrame(columns=[\"sampling_n\",\"alpha\",\"num_agg\",\"accuracy\",\"size\"])\r\n",
        "\r\n",
        "for path,alpha in zip(pickles_path,alpha_list):\r\n",
        "\r\n",
        "    # alpha=○○で作成したデータセットを読み込む\r\n",
        "    train_eval_all = pd.read_pickle(path,compression=\"gzip\")\r\n",
        "    train_eval_all.reset_index(drop=True,inplace=True)\r\n",
        "\r\n",
        "    unique_text_ids = list(train_eval_all.text_id.unique())\r\n",
        "    raw_aug_id = train_eval_all.loc[train_eval_all.raw_flg==1,\"aug_id\"].unique()[0]\r\n",
        "\r\n",
        "    for sampling_n in sampling_list:\r\n",
        "        \r\n",
        "        # データの件数を絞る\r\n",
        "        random.seed(0)\r\n",
        "        text_id_list = random.sample(unique_text_ids,sampling_n)\r\n",
        "        text_id_sampled = train_eval_all[train_eval_all.text_id.isin(text_id_list)]\r\n",
        "        \r\n",
        "        for i ,num_agg in enumerate(num_agg_list):\r\n",
        "\r\n",
        "            # num_agg=0（EDAなし）は最初の一回のみ\r\n",
        "            if alpha!=alpha_list[0] and num_agg==0:\r\n",
        "                continue\r\n",
        "            \r\n",
        "            # 各文章について、EDAを行った文章n件 + 原文を抽出\r\n",
        "            aug_ids = list(text_id_sampled.loc[text_id_sampled.raw_flg==0,\"aug_id\"].unique())\r\n",
        "            random.seed(0)\r\n",
        "            aug_id_list = random.sample(aug_ids,num_agg)\r\n",
        "            aug_id_list.append(raw_aug_id) #原文を追加\r\n",
        "            train_eval_df = text_id_sampled.loc[text_id_sampled.aug_id.isin(aug_id_list),[\"text\",\"label_index\"]]\r\n",
        "\r\n",
        "            # モデリング、精度算出\r\n",
        "            acc = modeling(train_eval_df,test_df)\r\n",
        "\r\n",
        "            # 結果の保存\r\n",
        "            idx = len(result)\r\n",
        "            result.loc[idx] = [sampling_n, alpha, num_agg, acc,len(train_eval_df)]\r\n",
        "            display(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQAOYKH-L3cZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}